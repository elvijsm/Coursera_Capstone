{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "<font size = 3>\n",
    "\n",
    "1. <a href=\"#item1\">Data Scraping and Cleaning</a>\n",
    "\n",
    "2. <a href=\"#item2\">Merging Geolocation Data</a>\n",
    "\n",
    "3. <a href=\"#item3\">Neighborhood Clustering</a>\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item1'></a>\n",
    "## Part 1: Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\"\n",
    "rawdf = tables = pd.read_html(url)[0] # Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns (prepend 'M')\n",
    "df = rawdf.rename(columns = dict([(i, \"M%d\" % (i + 1)) for i in range(rawdf.shape[1])]))\n",
    "\n",
    "# Rename indeces (extract first 2 characters from first column entries)\n",
    "df.rename(index = dict([(i, df.iloc[i, 0][2]) for i in range(rawdf.shape[0])]), inplace = True)\n",
    "\n",
    "# Remove FSAs (first 3 characters) from entries\n",
    "df = df.applymap(lambda x: x[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert data into desired format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "data = [] # Entries of the resulting dataframe\n",
    "for col in df.columns:\n",
    "    for row in df.index:\n",
    "        entry = df.loc[row, col]    # Cell at this index and column\n",
    "        if entry != 'Not assigned': # Ignore missing entries\n",
    "            # Extract boroughs. Conditions:\n",
    "            # 1. Keep only first part of a borough.\n",
    "            # E.g. \"North York (Don Mills) South (Flemingdon Park)\" (M3C) becomes \"North York\"\n",
    "            # 2. If there are no neighbourhoods in parentheses, take the entry to be a borough\n",
    "            borough, _ = entry.split(\"(\", 1)[0] if \"(\" in entry else entry, _\n",
    "\n",
    "            # Find all neighbourhoods (all entries surrounded by parentheses)\n",
    "            neighborhoods = re.findall(r'\\((.*?)\\)', entry)\n",
    "            # 1. Concatenate if there are multiple, e.g. \"Don Mills / Flemingdon Park\"\n",
    "            # 2. Replace slash separator with comma\n",
    "            # 3. Take borough if none\n",
    "            neighborhoods = \" / \".join(neighborhoods).replace(\" / \", \", \")\n",
    "\n",
    "            data.append([col + row, borough, neighborhoods if neighborhoods else borough])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append rows to dataframe\n",
    "fsa = pd.DataFrame(data, columns = ['PostalCode', 'Borough', 'Neighborhood'])\n",
    "fsa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some boroughs seem to be a special case of more common boroughs\n",
    "fsa.Borough.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boroughs that appear more than once\n",
    "boroughs = fsa.Borough.value_counts() \\\n",
    "    .reset_index(name = \"count\").query(\"count > 1\")[\"index\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace single occurrence boroughs with their parent if possible\n",
    "for b in boroughs:\n",
    "    fsa.loc[fsa.Borough.str.startswith(b), \"Borough\"] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsa.Borough.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape of data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item2'></a>\n",
    "## Part 2: Merge Geolocation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geocoder\n",
    "\n",
    "def get_coords_from_geocoder(postal_code):\n",
    "    # initialize your variable to None\n",
    "    lat_lng_coords = None\n",
    "\n",
    "    # loop until you get the coordinates\n",
    "    i = 0\n",
    "    while(lat_lng_coords is None):\n",
    "        g = geocoder.google('{}, Toronto, Ontario'.format(postal_code))\n",
    "        lat_lng_coords = g.latlng\n",
    "        i += 1\n",
    "        if (i == 10):\n",
    "            print(\"Could not get coordinates for {} within 10 tries\".format(postal_code))\n",
    "            break\n",
    "\n",
    "    return lat_lng_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_geocoder = False # Geocoder doesn't work\n",
    "\n",
    "if use_geocoder:\n",
    "    for code in fsa.PostalCode.values:\n",
    "        lat_lng_coords = get_coords_from_geocoder(code)\n",
    "        if lat_lng_coords is not None:\n",
    "            fsa.loc[fsa.PostalCode == code, \"Latitude\"] = lat_lng_coords[0]\n",
    "            fsa.loc[fsa.PostalCode == code, \"Longitude\"] = lat_lng_coords[1]\n",
    "else:\n",
    "    # Read geospatial data from csv\n",
    "    coords = pd.read_csv(\"https://cocl.us/Geospatial_data/Geospatial_coordinates.csv\")\n",
    "    \n",
    "    print(\"Data Frames are compatible\"\n",
    "          if list(fsa.PostalCode.values) == list(coords.loc[:, \"Postal Code\"].values)\n",
    "          else \"Data Frames are not compatible!\")\n",
    "    \n",
    "    # Merge data frames on Postal Code\n",
    "    fsa = fsa.merge(coords, left_on = \"PostalCode\", right_on = \"Postal Code\") \\\n",
    "        .drop(\"Postal Code\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe with geolocation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item3'></a>\n",
    "## Part 3: Neighborhood Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "from geopy.geocoders import Nominatim\n",
    "from sklearn.cluster import KMeans\n",
    "import folium\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider only neighbourhoods in outer Toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only boroughs NOT containing the word 'Toronto', also remove Queen's Park\n",
    "idx = (fsa.Borough != \"Queen's Park / Ontario Provincial Government\") & \\\n",
    "    (~fsa.Borough.str.contains(\"Toronto\"))\n",
    "outer = fsa.loc[idx, :].reset_index(drop = True)\n",
    "print(outer.shape)\n",
    "outer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geographical cooordinates of Toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"toronto_explorer\")\n",
    "location = geolocator.geocode('Toronto, Ontario')\n",
    "print('The geograpical coordinate of Toronto are {}, {}.'\n",
    "      .format(location.latitude, location.longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize outer Toronto neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of Toronto using latitude and longitude values\n",
    "map_outer = folium.Map(location=[location.latitude, location.longitude], zoom_start=10)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, label in zip(outer['Latitude'], outer['Longitude'], outer['Neighborhood']):\n",
    "    label = folium.Popup(label, parse_html = True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_outer)  \n",
    "    \n",
    "map_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foursquare Credentials and Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"foursquare.creds\", 'r') as creds:\n",
    "        CLIENT_ID, CLIENT_SECRET = creds.readline().split(\",\")\n",
    "        print(\"CLIENT_ID = {}\".format('*' * len(CLIENT_ID)))\n",
    "        print(\"CLIENT_SECRET = {}\".format('*' * len(CLIENT_SECRET)))\n",
    "except FileNotFoundError:\n",
    "    print(\"Make a 'foursquare.creds' file storing your Foursquare credentials!\")\n",
    "    CLIENT_ID = CLIENT_SECRET = ''\n",
    "\n",
    "VERSION = '20180605' # Foursquare API version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore neighborhoods of outer Toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use function from example notebook\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius = 750, LIMIT = 500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?' + \\\n",
    "        '&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, CLIENT_SECRET, VERSION, lat, lng, radius, LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        response = requests.get(url).json()[\"response\"]\n",
    "        # fixme: should use a try, except block here\n",
    "        results = response['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_venues = getNearbyVenues(names = outer['Neighborhood'],\n",
    "                              latitudes = outer['Latitude'],\n",
    "                              longitudes = outer['Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outer_venues.shape)\n",
    "outer_venues.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of venues for each neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(outer_venues.groupby('Neighborhood')[\"Venue\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} uniques categories.'.format(len(outer_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze Each Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "outer_onehot = pd.get_dummies(outer_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "outer_onehot['Neighborhood'] = outer_venues['Neighborhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [outer_onehot.columns[-1]] + list(outer_onehot.columns[:-1])\n",
    "outer_onehot = outer_onehot[fixed_columns]\n",
    "\n",
    "print(outer_onehot.shape)\n",
    "outer_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group rows by neighborhood and by taking the mean of the frequency of occurrence of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_grouped = outer_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "outer_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some neighborhoods have only a couple of venues. Discard such neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_venues = 10\n",
    "\n",
    "outer_grouped['count'] = outer_onehot.groupby('Neighborhood').size().values\n",
    "outer_grouped = outer_grouped.loc[outer_grouped['count'] >= min_venues, :]\\\n",
    "    .drop(\"count\", axis = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all categories without an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_grouped = outer_grouped.loc[:, (outer_grouped != 0).any(axis = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_grouped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get each neighborhood along with the top 10 most common venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort venues in descending order\n",
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    if ind < len(indicators):\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    else:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighborhoods_venues_sorted['Neighborhood'] = outer_grouped['Neighborhood']\n",
    "\n",
    "for ind in np.arange(outer_grouped.shape[0]):\n",
    "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(outer_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters\n",
    "kclusters = 3\n",
    "\n",
    "outer_clustering = outer_grouped.drop('Neighborhood', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters = kclusters, random_state = 0, n_init = 100).fit(outer_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add cluster label to the top 10 venues for each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "neighborhoods_venues_sorted.insert(0, 'Cluster', kmeans.labels_)\n",
    "\n",
    "# Neighborhoods with at least 10 venues\n",
    "neighborhoods = neighborhoods_venues_sorted.Neighborhood.values\n",
    "\n",
    "# The merge is more complicated than in the example notebook because:\n",
    "# 1. Not all venues were kept for the clustering\n",
    "# 2. Some neighborhoods span across multiple postal codes. Thus we take the mean coordinates\n",
    "outer_merged = (outer    \n",
    "    # Filter for remaining neighborhoods\n",
    "    .loc[outer.Neighborhood.isin(neighborhoods), :]\\\n",
    "    # Take mean coordinates\n",
    "    .groupby('Neighborhood').mean().reset_index()\\\n",
    "    .join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n",
    ")\n",
    "\n",
    "outer_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the resulting clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "map_clusters = folium.Map(location=[location.latitude, location.longitude], zoom_start=10)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(outer_merged['Latitude'], outer_merged['Longitude'], outer_merged['Neighborhood'], outer_merged['Cluster']):\n",
    "    label = folium.Popup(str(poi) + ' (Cluster {})'.format(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_merged.loc[outer_merged['Cluster'] == 0, outer_merged.columns[[0] + list(range(4, outer_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_merged.loc[outer_merged['Cluster'] == 1, outer_merged.columns[[0] + list(range(4, outer_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_merged.loc[outer_merged['Cluster'] == 2, outer_merged.columns[[0] + list(range(4, outer_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustering results are underwhelming, it's hard to find an interpretation for the resulting clusters (the last one could perhaps be described as 'Neighborhoods with pizza places and other fast food'). Perhaps because there are relatively few venues in most neighborhoods of outer Toronto, such that the number of categories is much larger than the number of neighborhoods.\n",
    "\n",
    "A more interesting outcome might be obtained by aggregating categories, e.g. by adding up restaurants, fast food places, shops, recreation venues, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
